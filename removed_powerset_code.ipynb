{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code for removed powerset steps\n",
    "This code will not run properly in this workbook, and is just saved as reference of a path taken, but ultimately not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, I thought I would iterate through all the features, and then test out different combinations\n",
    "# In hindsight, I should have just looked at variable importances, and perhaps made a decision that way\n",
    "# This takes about 2 minutes to run\n",
    "all_attributes = ['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O', 'reward', 'difficulty', 'duration', 'web','social','email','mobile','amt_per_day_increases']\n",
    "target = 'amt_per_day_increases'\n",
    "top_acc = 0.0\n",
    "best_acc = 0.0\n",
    "cur_acc = 0.0\n",
    "\n",
    "# Iterate through the offer types\n",
    "for strType in strTypes[1:]:\n",
    "    df = df_sum[df_sum['offer_'+strType]==1][all_attributes]\n",
    "    top_acc = 0.0\n",
    "    top_attr = []\n",
    "    \n",
    "    print('\\nOffer type: {}'.format(strType))\n",
    "    \n",
    "    # Iterate through the attributes 5 times\n",
    "    for iteration in range(5):\n",
    "        cur_attr = []\n",
    "        best_acc = 0.0\n",
    "        y = df[target]\n",
    "        \n",
    "        # Iterate through the attributes, adding one in, testing the combination\n",
    "        # Then deciding whether the attribute helped the model or not\n",
    "        # dropping it if it didn't improve it\n",
    "        for attr in all_attributes[:-1]:\n",
    "            cur_attr.append(attr)\n",
    "            X = df[cur_attr]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y)        \n",
    "            mdl, y_pred = create_RF_model(X_train,y_train,X_test)\n",
    "    \n",
    "            cur_acc = (y_pred == y_test).mean()\n",
    "            \n",
    "            if cur_acc > best_acc:\n",
    "                best_acc = cur_acc\n",
    "                \n",
    "            else:\n",
    "                cur_attr.pop(-1)\n",
    "                \n",
    "        if best_acc > top_acc:\n",
    "            top_acc = best_acc\n",
    "            top_attr = cur_attr\n",
    "            \n",
    "        print(\"\\tIteration: {}. The best combination found was: {} and it's accuracy was: {}%\".format(iteration + 1, cur_attr, str(best_acc*100)[:4]))\n",
    "    print(\"\\tThe Top accuracy was: {} for: {}\".format(str(top_acc*100)[:4], top_attr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original results\n",
    "Offer type: bogo<br>\n",
    "\tIteration: 1. The best combination found was: ['age', 'email'] and it's accuracy was: 64.6%<br>\n",
    "\tIteration: 2. The best combination found was: ['age', 'tenure_years', 'gender_O'] and it's accuracy was: 65.8%<br>\n",
    "\tIteration: 3. The best combination found was: ['age', 'tenure_years', 'reward'] and it's accuracy was: 66.3%<br>\n",
    "\tIteration: 4. The best combination found was: ['age', 'tenure_years', 'reward', 'difficulty', 'social'] and it's accuracy was: 65.2%<br>\n",
    "\tIteration: 5. The best combination found was: ['age', 'tenure_years', 'gender_M', 'reward', 'web', 'social', 'mobile'] and it's accuracy was: 65.0%<br>\n",
    "\tThe Top accuracy was: 66.3 for: ['age', 'tenure_years', 'reward']<br><br>\n",
    "\n",
    "Offer type: discount<br>\n",
    "\tIteration: 1. The best combination found was: ['age', 'gender_O', 'web'] and it's accuracy was: 61.8%<br>\n",
    "\tIteration: 2. The best combination found was: ['age', 'email'] and it's accuracy was: 64.3%<br>\n",
    "\tIteration: 3. The best combination found was: ['age', 'web'] and it's accuracy was: 67.0%<br>\n",
    "\tIteration: 4. The best combination found was: ['age', 'web'] and it's accuracy was: 61.8%<br>\n",
    "\tIteration: 5. The best combination found was: ['age', 'gender_O', 'web', 'email'] and it's accuracy was: 65.0%<br>\n",
    "\tThe Top accuracy was: 67.0 for: ['age', 'web']<br><br>\n",
    "\n",
    "Offer type: informational<br>\n",
    "\tIteration: 1. The best combination found was: ['age', 'income', 'gender_M'] and it's accuracy was: 57.1%<br>\n",
    "\tIteration: 2. The best combination found was: ['age'] and it's accuracy was: 58.1%<br>\n",
    "\tIteration: 3. The best combination found was: ['age', 'income', 'gender_M'] and it's accuracy was: 56.3%<br>\n",
    "\tIteration: 4. The best combination found was: ['age', 'income', 'tenure_years', 'gender_M', 'web'] and it's accuracy was: 58.1%<br>\n",
    "\tIteration: 5. The best combination found was: ['age', 'tenure_years', 'reward'] and it's accuracy was: 64.9%<br>\n",
    "\tThe Top accuracy was: 64.9 for: ['age', 'tenure_years', 'reward']<br><br>\n",
    "<b>Thought:</b> Although this method did show some variation, there is an issue with me having a particular order it is running through\n",
    "I am going to run through every comination of a subset, and see what results we get\n",
    "<br>\n",
    "### Powerset iterations\n",
    "<b>Iteration 1:</b><br> \n",
    "powerset of ['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O','reward']<br>\n",
    "Run time: About 2 minutes (Start: 2020-05-01 22:51:09.034462, Stop: 2020-05-01 22:52:51.304712)<br>\n",
    "Bogo: The Top accuracy was: 69.6 for: ['age', 'gender_O', 'reward']<br>\n",
    "Discount: The Top accuracy was: 81.7 for: ['gender_O']<br>\n",
    "Informational: The Top accuracy was: 85.6 for: ['reward']<br>\n",
    "<br>\n",
    "<b>Iteration 2:</b><br> \n",
    "powerset of ['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O','reward', 'difficulty', 'duration', 'web','social','email','mobile']<br>\n",
    "Run time: About 1 hour 39 minutes: Start: 2020-05-01 22:57:00.347090, Stop: 2020-05-02 00:36:08.271409\n",
    "Bogo: The Top accuracy was: 85.1 for: ['email']<br>\n",
    "Discount: The Top accuracy was: 83.5 for: ['web', 'email']<br>\n",
    "Informational: The Top accuracy was: 87.3 for: ['gender_F', 'mobile']<br>\n",
    "<b>Thought:</b> Something didn't seem right here, and I suspected the models were simplified to only produce Falses, so I tried again, but this time logging some information into a dataframe<br>\n",
    "<br>\n",
    "<b>Iteration 3:</b><br>\n",
    "Saved to: '.\\\\data\\\\RandomForest_Iteration_results.csv'<br>\n",
    "powerset of ['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O','reward', 'difficulty', 'duration', 'web','social','email','mobile']<br>\n",
    "Run Time: About 1 hour 40 minutes: Start: 2020-05-02 08:41:36.037257, Stop: 2020-05-02 10:22:25.310513<br>\n",
    "Bogo: The top accuracy where both True and False were present was: 75.4 for [gender_F, gender_O, web, email, mobile]<br>\n",
    "Discount: The top accuracy where both True and False were present was: 81.8 for [gender_O]<br>\n",
    "Informational: The top accuracy where both True and False were present was: 83.6 for [gender_F, gender_O, email]<br><br>\n",
    "<b>Thought: </b>The top results for Discount and Informationl make think there would be a lot of Falses. I will need to rebuild those models, and look for better matches, even though they would be less \"Accurate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# ------------WARNING-------------------------------------------------------------------------\n",
    "# This code was intentionally commented out\n",
    "# This step will take approx. 1 hour and 40 minutes to run\n",
    "# It runs through all combinations of attributes, building and scoring each random forest\n",
    "\n",
    "start_dtm = datetime.datetime.now()\n",
    "\n",
    "from itertools import chain, combinations\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "#This is for the full powerset. Do not use this unless you want your system to be running for the next hour and 40 minutes!\n",
    "pow_set = list(powerset(['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O','reward', 'difficulty', 'duration', 'web','social','email','mobile']))[1:] \n",
    "all_attributes = ['age', 'income', 'tenure_years', 'gender_M', 'gender_F', 'gender_O', 'reward', 'difficulty', 'duration', 'web','social','email','mobile','amt_per_day_increases']\n",
    "target = 'amt_per_day_increases'\n",
    "\n",
    "df_it = pd.DataFrame(columns=['offer_type','attributes','accuracy','labels','rec_ins_dt'])\n",
    "\n",
    "for strType in strTypes[1:]:\n",
    "    df = df_sum[df_sum['offer_'+strType]==1][all_attributes]\n",
    "    \n",
    "    y = df[target]\n",
    "\n",
    "    for attr_list in pow_set:\n",
    "        X = df[list(attr_list)]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        \n",
    "        mdl, y_pred = create_RF_model(X_train,y_train,X_test)\n",
    "\n",
    "        df_it = df_it.append({'offer_type':strType,'attributes':list(attr_list),'accuracy':(y_pred == y_test).mean(),'labels':np.unique(y_pred),'rec_ins_dt':datetime.datetime.now()}, ignore_index=True)\n",
    "    \n",
    "df_it.to_csv('.\\\\data\\\\RandomForest_Iteration_results.csv', index=False)\n",
    "stop_dtm = datetime.datetime.now()\n",
    "print('Start: {}\\nStop: {}'.format(start_dtm,stop_dtm))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code was used to scan for the top iterations concerning accuracy\n",
    "# And then to test below while saving the models\n",
    "\n",
    "# Read in the saved Iteration dataframe\n",
    "df_it = pd.read_csv('.\\\\data\\\\RandomForest_Iteration_results.csv')\n",
    "df_it[df_it['offer_type']=='bogo'].sort_values('accuracy',ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After some testing, I settled on what I thought were the best models\n",
    "# for actual production. I would recommend some cost benefit analysis to the \n",
    "# bogo offers though, if amount increases do not take into account cost to us\n",
    "\n",
    "# If you rerun this code multiple times, you can get some interesting results\n",
    "# where the model breaks down and offers too much. If you were using this for\n",
    "# production, you would want to iterate several times before accepting a given version\n",
    "\n",
    "def build_and_save_model(strType,attributes):\n",
    "    ''' Build a Random Forest model, print some summary information, and then save the model\n",
    "    INPUT: strType: offer type (bogo, discount, informational)\n",
    "        attributes: The attributes to be used as a list\n",
    "    OUTPUT: the generated Random Forest model\n",
    "    '''\n",
    "    df = df_sum[df_sum['offer_'+strType]==1][all_attributes].copy()\n",
    "    y = df[target]\n",
    "    X = df[attributes]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    mdl, y_pred = create_RF_model(X_train,y_train,X_test)\n",
    "    save_model(mdl, \".\\\\models\\\\\"+strType+\"_RandomForest_Model.pkl\")\n",
    "    \n",
    "    feature_importances = pd.DataFrame(list(mdl.feature_importances_) ,index = X_train.columns, columns=['importance']).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print('Model for {} offers'.format(strType))\n",
    "    print('accuracy: {}'.format((y_pred == y_test).mean()*100))\n",
    "    print('offers to: {}% of customers\\n'.format(round(y_pred.mean()*100,2)))\n",
    "    print('Variable importance\\n',feature_importances)\n",
    "    print('\\n')\n",
    "    return mdl\n",
    "\n",
    "# Set the feature lists to be used for each offer type\n",
    "bogo_features = ['gender_F', 'gender_O', 'web']\n",
    "discount_features = ['gender_O', 'social', 'mobile']\n",
    "informational_features = ['gender_F', 'gender_O']\n",
    "\n",
    "featureSets = {'bogo':bogo_features\n",
    "           ,'discount':discount_features\n",
    "           ,'informational':informational_features}\n",
    "\n",
    "# build a model for each offer type\n",
    "b_mdl = build_and_save_model('bogo',bogo_features)\n",
    "d_mdl = build_and_save_model('discount',discount_features)\n",
    "i_mdl = build_and_save_model('informational',informational_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
